# Bestandteile
## Dockerfile
‚û° [Link zum Dockerfile](https://github.com/cqNikolaus/JenkinsML/blob/main/data_extraction/Dockerfile)  
### Ablauf
Es wird ein Standard-Python-Image verwendet. Anschlie√üend werden die Python-Abh√§ngigkeiten `requests` (f√ºr API-Anfragen) und `pandas` (f√ºr die Datenaufbereitung) installiert.  

## Jenkinsfile
‚û° [Link zum Jenkinsfile](https://github.com/cqNikolaus/JenkinsML/blob/main/data_extraction/Jenkinsfile) 
### Ablauf
**1. Der Job nimmt zwei Pflichtparameter entgegen:**
- **TARGET_JOB_NAME**: Name des Jobs, dessen Build-Daten extrahiert werden sollen.
- **FIELDS_TO_INCLUDE**: Die Daten (Features), die extrahiert werden sollen. Der Default-Wert listet bereits alle verf√ºgbaren Features auf. Nicht ben√∂tigte k√∂nnen einfach entfernt werden. Das Feld `result_bin` ist dabei nicht gelistet, es wird automatisch immer extrahiert. Dabei handelt es sich um das "Label", das als prim√§rer Schl√ºssel f√ºr das Modelltraining dient. (1 = Build war erfolgreich, 0 = Build ist fehlgeschlagen). Alle anderen Features sind optional. Sollen die exportierten Daten anschlie√üend zum Modelltraining mit dem zugeh√∂rigen Job verwendet werden, m√ºssen mindestens die Felder `duration_sec`, `error_count` und `commits_count`
- [Liste aller Extrahierbaren Features](feature-list.md)

**2. Das Docker-Image wird gebaut**

**3. Der Container wird gestartet. Beim Start wird folgendes als Umgebungsvariablen in den Container √ºbergeben:**

- Das Jenkins-API-Token aus den Credentials der Jenkins Instanz.
- Die Parameter `TARGET_JOB_NAME` und `FIELDS_TO_INCLUDE`

**4. Das Skript [data_extraction.py](build-prognose-ml/extract-data.md) wird ausgef√ºhrt.**

**5. Die Standardausgabe des Skripts wird in die Datei `{TARGET_JOB_NAME}_build_data.csv` geschrieben und im Jenkins Workspace gespeichert.**

## extract_data.py
‚û° [Link zum Skript](https://github.com/cqNikolaus/JenkinsML/blob/main/data_extraction/extract_data.py)

### Ablauf

1. **Konfiguration der Jenkins-Verbindung**  
   - Es wird eine Klasse erstellt, die eine Verbindung zu Jenkins herstellt.  
   - Die URL der Jenkins-Instanz, der Benutzername, das API-Token und der Job-Name werden eingelesen bzw. gespeichert.  
   - Optional wird eine maximale Anzahl an Builds definiert, die abgerufen werden sollen.

2. **Generierung von URLs f√ºr API-Anfragen**  
   - URLs f√ºr Build-Daten und Konsolen-Logs werden basierend auf der Build-Nummer erzeugt.

3. **Abruf von Daten aus Jenkins**  
   - Das Skript sendet HTTP-Anfragen an Jenkins und holt die Build-Daten als JSON, sowie den Log des Builds.   

4. **Verarbeitung der Build-Daten**  
   - Das Skript liest die JSON-Daten eines Builds und extrahiert relevante Informationen.
   - Zus√§tzliche abgeleitete Features werden hergestellt, z.B. Verh√§ltnis von Commit-Autoren zu Fehler-Verantwortlichen. 
   - Anzahl der Fehler (`ERROR` oder `Exception`) im Log werden gez√§hlt und als `error_count` zur Verf√ºgung gestellt.  

5. **Abruf mehrerer Builds**  
   - Das Skript ruft nacheinander alle Builds bis zur definierten Maximalanzahl ab.  
   - Die Build-Daten werden in einer Liste gesammelt.

6. **Verarbeitung der Daten als DataFrame**  
   - Die Build-Daten werden in eine Tabelle (`pandas.DataFrame`) umgewandelt.  
   - Daten werden bereinigt, builds mit unbekanntem Ergebnis werden herausgefiltert.  
   - Falls eine Umgebungsvariable definiert, welche Spalten exportiert werden sollen, wird das hier ber√ºcksichtigt.  
   - Eine Bin√§rvariable (`0` oder `1`) f√ºr das Build-Ergebnis (`FAILURE` oder nicht) wird hinzugef√ºgt.

8. **Ausgabe der Daten als CSV**  
   - Die gefilterten Daten werden als CSV ausgegeben (standardm√§√üig in die Konsole).  
   - Falls keine Daten vorhanden sind, wird das Skript mit einer Fehlermeldung beendet.  

Am Ende hat man also eine detaillierte Tabelle mit allen relevanten Informationen √ºber die letzten Builds aus Jenkins. üöÄ
